{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kelompok 1\n",
    "# Nama Anggota\n",
    "# 1. NANDA PUTRI RAHMAWATI (2011016320021)\n",
    "# 2. HELMA MUKIMAH (2211016220008)\n",
    "# 3. NORKHADIJAH (2211016220030)\n",
    "# 4. FAUZAN SAPUTRA (2211016310003)\n",
    "# Link GDrive data dan output = https://drive.google.com/drive/folders/1-dgVW5mK2UjWzQTQIz2j16YxZ6oczWcy?usp=drive_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = pd.read_csv('lung_cancer_examples.csv')\n",
    "S = S.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = S[:, 2:6]  # Input features (Age, Smokes, AreaQ, Alkhol)\n",
    "y = S[:, 6]    # Labels (Result)\n",
    "\n",
    "# Ensure that the labels are integers\n",
    "y = y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=3, random_state=0, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "# Initialize K-Fold cross-validation\n",
    "kf = KFold(n_splits=3, random_state=0, shuffle=True)\n",
    "\n",
    "print(kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1, Fold 1 classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        11\n",
      "           1       1.00      0.89      0.94         9\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.96      0.94      0.95        20\n",
      "weighted avg       0.95      0.95      0.95        20\n",
      "\n",
      "k = 1, Fold 2 classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.93         8\n",
      "           1       0.92      1.00      0.96        12\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.96      0.94      0.95        20\n",
      "weighted avg       0.95      0.95      0.95        20\n",
      "\n",
      "k = 1, Fold 3 classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92        12\n",
      "           1       0.86      0.86      0.86         7\n",
      "\n",
      "    accuracy                           0.89        19\n",
      "   macro avg       0.89      0.89      0.89        19\n",
      "weighted avg       0.89      0.89      0.89        19\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 2, Fold 1 classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        11\n",
      "           1       1.00      0.89      0.94         9\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.96      0.94      0.95        20\n",
      "weighted avg       0.95      0.95      0.95        20\n",
      "\n",
      "k = 2, Fold 2 classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.88      0.78         8\n",
      "           1       0.90      0.75      0.82        12\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.80      0.81      0.80        20\n",
      "weighted avg       0.82      0.80      0.80        20\n",
      "\n",
      "k = 2, Fold 3 classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88        12\n",
      "           1       0.83      0.71      0.77         7\n",
      "\n",
      "    accuracy                           0.84        19\n",
      "   macro avg       0.84      0.82      0.82        19\n",
      "weighted avg       0.84      0.84      0.84        19\n",
      "\n",
      "k = 3, Fold 1 classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n",
      "k = 3, Fold 2 classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88         8\n",
      "           1       0.92      0.92      0.92        12\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.90      0.90      0.90        20\n",
      "weighted avg       0.90      0.90      0.90        20\n",
      "\n",
      "k = 3, Fold 3 classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88        12\n",
      "           1       0.83      0.71      0.77         7\n",
      "\n",
      "    accuracy                           0.84        19\n",
      "   macro avg       0.84      0.82      0.82        19\n",
      "weighted avg       0.84      0.84      0.84        19\n",
      "\n",
      "k = 4, Fold 1 classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        11\n",
      "           1       1.00      0.89      0.94         9\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.96      0.94      0.95        20\n",
      "weighted avg       0.95      0.95      0.95        20\n",
      "\n",
      "k = 4, Fold 2 classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.88      0.74         8\n",
      "           1       0.89      0.67      0.76        12\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.76      0.77      0.75        20\n",
      "weighted avg       0.79      0.75      0.75        20\n",
      "\n",
      "k = 4, Fold 3 classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85        12\n",
      "           1       0.80      0.57      0.67         7\n",
      "\n",
      "    accuracy                           0.79        19\n",
      "   macro avg       0.79      0.74      0.76        19\n",
      "weighted avg       0.79      0.79      0.78        19\n",
      "\n",
      "k = 5, Fold 1 classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n",
      "k = 5, Fold 2 classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.82         8\n",
      "           1       0.91      0.83      0.87        12\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.84      0.85      0.85        20\n",
      "weighted avg       0.86      0.85      0.85        20\n",
      "\n",
      "k = 5, Fold 3 classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85        12\n",
      "           1       0.80      0.57      0.67         7\n",
      "\n",
      "    accuracy                           0.79        19\n",
      "   macro avg       0.79      0.74      0.76        19\n",
      "weighted avg       0.79      0.79      0.78        19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop over different values of k\n",
    "results = {}  # Dictionary to store results for each k\n",
    "\n",
    "for k in range(1, 6):\n",
    "    neigh2 = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\n",
    "\n",
    "    # Initialize arrays to store accuracy, precision, and recall for each fold\n",
    "    avg_acc = np.zeros(5)\n",
    "    avg_pre = np.zeros(5)\n",
    "    avg_rec = np.zeros(5)\n",
    "\n",
    "    # Cross-validation loop\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Train the classifier\n",
    "        neigh2.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = neigh2.predict(X_test)\n",
    "\n",
    "        # Calculate and store metrics\n",
    "        avg_acc[i] = accuracy_score(y_test, y_pred)\n",
    "        avg_pre[i] = precision_score(y_test, y_pred, average='macro')\n",
    "        avg_rec[i] = recall_score(y_test, y_pred, average='macro')\n",
    "\n",
    "        # Print classification report for the current fold\n",
    "        print(f\"k = {k}, Fold {i+1} classification report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    # Store the average metrics for the current value of k\n",
    "    results[k] = {\n",
    "        \"average_accuracy\": np.mean(avg_acc),\n",
    "        \"average_precision\": np.mean(avg_pre),\n",
    "        \"average_recall\": np.mean(avg_rec)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for k = 1:\n",
      "Average Accuracy:  0.5589473684210526\n",
      "Average Precision:  0.5613553113553114\n",
      "Average Recall:  0.5537698412698413\n",
      "\n",
      "Results for k = 2:\n",
      "Average Accuracy:  0.5184210526315789\n",
      "Average Precision:  0.5196153846153846\n",
      "Average Recall:  0.5144841269841269\n",
      "\n",
      "Results for k = 3:\n",
      "Average Accuracy:  0.5484210526315789\n",
      "Average Precision:  0.5471153846153846\n",
      "Average Recall:  0.5422619047619047\n",
      "\n",
      "Results for k = 4:\n",
      "Average Accuracy:  0.4978947368421053\n",
      "Average Precision:  0.5027633477633477\n",
      "Average Recall:  0.49186507936507934\n",
      "\n",
      "Results for k = 5:\n",
      "Average Accuracy:  0.5278947368421052\n",
      "Average Precision:  0.5272582972582972\n",
      "Average Recall:  0.5196428571428571\n",
      "\n",
      "The best k is 1 with an average accuracy of 0.5589473684210526\n"
     ]
    }
   ],
   "source": [
    "# Print results for each k and determine the best k based on average accuracy\n",
    "best_k = 1\n",
    "best_accuracy = 0\n",
    "\n",
    "for k in results:\n",
    "    print(f\"Results for k = {k}:\")\n",
    "    print(\"Average Accuracy: \", results[k][\"average_accuracy\"])\n",
    "    print(\"Average Precision: \", results[k][\"average_precision\"])\n",
    "    print(\"Average Recall: \", results[k][\"average_recall\"])\n",
    "    print()\n",
    "    # Determine the best k based on the highest average accuracy\n",
    "    if results[k][\"average_accuracy\"] > best_accuracy:\n",
    "        best_accuracy = results[k][\"average_accuracy\"]\n",
    "        best_k = k\n",
    "\n",
    "print(f\"The best k is {best_k} with an average accuracy of {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for new data with k = 1: Non Cancer\n",
      "Prediction for new data with k = 2: Non Cancer\n",
      "Prediction for new data with k = 3: Non Cancer\n",
      "Prediction for new data with k = 4: Non Cancer\n",
      "Prediction for new data with k = 5: Non Cancer\n"
     ]
    }
   ],
   "source": [
    "# Test new data\n",
    "# Example test data\n",
    "new_data = np.array([[43 , 17, 6, 0]])  # Example new data based on provided format\n",
    "\n",
    "# Print prediction for new data with the best k\n",
    "# neigh2 = KNeighborsClassifier(n_neighbors=best_k, metric='euclidean')\n",
    "# neigh2.fit(X, y)  # Fit the model on the entire dataset\n",
    "# new_prediction = neigh2.predict(new_data)\n",
    "# print(f\"Prediction for new data with k = {best_k}:\", new_prediction)\n",
    "\n",
    "# Loop k = 1 to k = 5 to predict the class for the new data\n",
    "for k in range(1, 6):\n",
    "    # Create the KNeighborsClassifier with k neighbors\n",
    "    neigh2 = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\n",
    "    \n",
    "    # Fit the model on the entire dataset\n",
    "    neigh2.fit(X, y)\n",
    "    \n",
    "    # Predict the class for the new data\n",
    "    new_prediction = neigh2.predict(new_data)\n",
    "    \n",
    "    # Determine label based on prediction\n",
    "    if new_prediction == 1:\n",
    "        label = 'Cancer'\n",
    "    else:\n",
    "        label = 'Non Cancer'\n",
    "    \n",
    "    # Print the prediction result\n",
    "    print(f\"Prediction for new data with k = {k}:\", label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
